---
title: "p8105_hw5_ts3349"
author: "Tessa Senders"
date: "11/9/2020"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load libraries}
library(tidyverse)
library(purrr)
library(stringr)
```


## Problem 1


```{r prob 1 part 1}
homicide_df =
  read_csv("homicide_data/homicide-data.csv") %>%
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
    disposition == "Closed without arrest" ~ "unsolved",
    disposition == "Open/No arrest" ~ "unsolved",
    disposition == "Closed by arrest" ~ "solved",
  )
) %>%
  select(city_state, resolved) %>%
  filter(city_state != "Tulsa_AL")
```

The raw data regarding homicides in all 50 states in the USA comes from the Washington Post GitHub repository.  The data includes, the victim's name, race, and age.  The data also includes the city, the state, the latitude, and the longitude of the homicide and the disposition (whether the homicide is Closed by arrest, Open/No arrest, or Closed without arrest).  The data has `r nrow(homicide_df)` entries.

```{r prob 1 part 2}
aggregate_df = homicide_df %>%
  group_by(city_state) %>%
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  ) 
```

```{r prob 1 part 3}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved),
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>%
  broom::tidy()
```

```{r prob 1 part 4}
results_df = aggregate_df %>%
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>%
  select(-prop_tests) %>%
  unnest(tidy_tests) %>%
  select(city_state, estimate, conf.low, conf.high) 

head(results_df)
```

```{r prob 1 part 5}
results_df %>%
  mutate(city_state = fct_reorder(city_state, estimate)) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text = element_text(angle = 270, vjust = 0.5, hjust = 1)) +
  labs(
    title = "Confidence Intervals for The Proportion of \n Unsolved Homicides in Various Cities",
    x = "City and State",
    y = "Proportion Estimate",
    caption = "Data from the Washington Post GitHub")
```


## Problem 2


```{r prob 2 part 1}
path_df = 
tibble(
path = list.files("lda_data"))

longitudinal_study_df = path_df %>%
  mutate(
    path = str_c("lda_data/", path),
    data = map(.x = path, ~read_csv(.x))
) %>%
  unnest(data) %>%
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "observation"
  ) %>%
  mutate(
    week = as.numeric(str_replace(week, "week_", "")),
    arm = str_extract(path, "/[a-z][a-z][a-z]"),
    arm = str_remove(arm, "/"),
    id = str_extract(path, "[0-9]+")
  ) %>%
  select(-path)

```


```{r prob 2 plot}
 longitudinal_study_df %>% ggplot(aes(x = week, y = observation, color = id, linetype = arm)) +
  geom_line() +
  labs(
    title = "Observations for Each Subject Over 8 Weeks",
    x = "Week Number",
    y = "Observation Value",
    caption = "Data from a longitudinal study that included \n a control arm and an experimental arm. \n  ID # 01-05 are the control arm and \n ID # 06-10 are the experimental arm.")
```

The plot shows that the subjects from the experimental arm (ids 01-05) tend to have higher observed values over time (increasing values over time) than the subjects from the control arm (ids 06-10).  The observed values for the subjects in the control arm tend to stay fairly constant over time. 


## Problem 3


```{r prob 3 part 1}
set.seed(1)

sim_datasets = function(mu) {
  
    x = rnorm(n = 30, mean = mu, sd = 5)
  
  t.test(x = x, mu = 0, alternative = "two.sided") %>% 
    broom::tidy() %>% select(estimate, p.value)
}


sim_results = tibble(
  mu = c(0, 1, 2, 3, 4, 5, 6) 
  ) %>%
  mutate(output_lists = map(.x = mu, ~rerun(5000, sim_datasets(mu = .x)))
         ) %>%
  unnest(output_lists) %>%
  unnest(output_lists) %>%
  mutate(reject_null = if_else(p.value < 0.05, 1, 0))
```


```{r prob 3 plot 1}
sim_results %>% 
  group_by(mu) %>%
  summarize(prop_reject = sum(reject_null)/5000) %>%
  ggplot(aes(x = mu, y = prop_reject)) +
  geom_line() +
  labs(
    title = "The Proportion of Times the Null was Rejected for Each mu",
    x = "mu",
    y = "Proportion of Times the Null was Rejected",
    caption = "Data is the result of generating 5000 datasets \n from a normal distribution with a sample size of 30 \n and standard deviation of 5 for each of 7 different mu values (0-6).")
```

As the effect size increases, the power increases.  Since the standard deviation is the same for the datasets for each mu, the only part of the effect size that is changing is the difference between the actual mu and the null mu.  As the difference between the null mu (0) and the actual mu increases, the power also increases.


```{r prob 3 plot 2}
avg_vs_true_plot = sim_results %>% 
  group_by(mu) %>%
  summarize(mean_mu_hat = mean(estimate)) %>%
  ggplot(aes(x = mu, y = mean_mu_hat)) +
  geom_line() +
  labs(
    title = "The Average Estimate of mu versus the True Value of mu",
    x = "True Value of mu",
    y = "Average Estimate of mu",
    caption = "Data is the result of generating 5000 datasets \n from a normal distribution with a sample size of 30 \n and standard deviation of 5 for each of 7 different mu values (0-6).")
```


```{r prob 3 plot 3}
avg_rejected_vs_true_plot = sim_results %>% 
  filter(reject_null == 1) %>%
  group_by(mu) %>%
  summarize(mean_mu_hat = mean(estimate)) %>%
  ggplot(aes(x = mu, y = mean_mu_hat)) +
  geom_line() +
  labs(
    title = "The Average Estimate of mu \n (only for samples which the null was rejected) \n versus the True Value of mu",
    x = "True Value of mu",
    y = "Average Estimate of mu \n (only for samples which the null was rejected)",
    caption = "Data is the result of generating 5000 datasets \n from a normal distribution with a sample size of 30 \n and standard deviation of 5 for each of 7 different mu values (0-6).")
```

```{r prob 3 plots combined}
avg_vs_true_plot
avg_rejected_vs_true_plot
```


The sample average mu across tests for which the null is rejected is approximately equal to the true value of mu because when the null (mu = 0) is rejected that means the estimate is closer to the true mu (except for when the true mu is 0).





